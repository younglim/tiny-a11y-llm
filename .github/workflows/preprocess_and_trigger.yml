name: Preprocess and Upload Hugging Face Dataset

on:
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * 0"  # Weekly dataset update

jobs:
  prepare-dataset:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install datasets huggingface_hub markdown-it-py

      - name: Fetch WCAG and MDN data
        run: |
          python data/fetch_wcag.py
          python data/fetch_mdn.py

      - name: Upload merged dataset to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python - <<'EOF'
          from datasets import load_from_disk, concatenate_datasets

          print("ðŸ”„ Loading local datasets...")
          ds1 = load_from_disk("datasets/wcag_prepared")   # Dataset object
          ds2 = load_from_disk("datasets/mdn_prepared")    # Dataset object

          # Merge datasets
          merged = concatenate_datasets([ds1, ds2])

          repo_id = "younglim/a11y-dataset"
          print(f"ðŸ“¤ Uploading merged dataset to {repo_id}...")
          merged.push_to_hub(
              repo_id,
              private=False,
              commit_message="Auto-update from GitHub Actions",
              revision="main"
          )
          print("âœ… Dataset uploaded successfully.")
          EOF
